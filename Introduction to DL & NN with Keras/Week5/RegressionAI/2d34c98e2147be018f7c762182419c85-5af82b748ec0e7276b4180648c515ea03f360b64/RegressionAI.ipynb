{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING A REGRESSION MODEL IN KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and explore the data set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X are predictors and y is the outcome (splitting the dataset into predictors and target/outcome)\n",
    "\n",
    "X = concrete_data.drop(columns=[\"Strength\"])\n",
    "y = concrete_data[\"Strength\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A - Model creation, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are split into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 1s 716us/step - loss: 234927.0606\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 303us/step - loss: 84246.3167\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 301us/step - loss: 22684.6225\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 225us/step - loss: 8425.9475\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 306us/step - loss: 6671.9016\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 278us/step - loss: 6285.0809\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 470us/step - loss: 5641.8038\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 276us/step - loss: 5007.6141\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 254us/step - loss: 4483.8509\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 288us/step - loss: 4022.1695\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 323us/step - loss: 3628.3695\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 308us/step - loss: 3254.4973\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 335us/step - loss: 2924.7262\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 303us/step - loss: 2629.4963\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 286us/step - loss: 2350.9054\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 306us/step - loss: 2103.7284\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 290us/step - loss: 1880.7171\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 307us/step - loss: 1673.4250\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 386us/step - loss: 1503.8104\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 277us/step - loss: 1347.4236\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 328us/step - loss: 1194.7416\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 281us/step - loss: 1068.1997\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 304us/step - loss: 956.3706\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 334us/step - loss: 851.8268\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 282us/step - loss: 761.6845\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 419us/step - loss: 685.9718\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 255us/step - loss: 612.2064\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 361us/step - loss: 548.2303\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 249us/step - loss: 493.4492\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 298us/step - loss: 442.4527\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 220us/step - loss: 401.2005\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 223us/step - loss: 362.4609\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 247us/step - loss: 329.9484\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 355us/step - loss: 302.1835\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 282us/step - loss: 275.9019\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 309us/step - loss: 256.1927\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 328us/step - loss: 236.5050\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 306us/step - loss: 222.1560\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 384us/step - loss: 207.7277\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 303us/step - loss: 197.2457\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 331us/step - loss: 186.7754\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 337us/step - loss: 178.3768\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 388us/step - loss: 169.6591\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 607us/step - loss: 162.0914\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 331us/step - loss: 158.8096\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 279us/step - loss: 152.7361\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 334us/step - loss: 147.5064\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 554us/step - loss: 144.5618\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 531us/step - loss: 140.6491\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 326us/step - loss: 138.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f451e112898>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on the test data is 172.083\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error on the test data is %.3f\" %(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated steps 1-3 50 times using a for-loop\n",
    "## With means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MsqE1: 97.45278012173847\n",
      ".MsqE2: 125.51388426351701\n",
      ".MsqE3: 108.26858540260291\n",
      ".MsqE4: 121.31393872109817\n",
      ".MsqE5: 132.92334567073092\n",
      ".MsqE6: 123.0597766271301\n",
      ".MsqE7: 134.2143368520397\n",
      ".MsqE8: 110.45137018987661\n",
      ".MsqE9: 138.53962218645708\n",
      ".MsqE10: 110.0513467140568\n",
      ".MsqE11: 104.37951931752819\n",
      ".MsqE12: 98.48648212025466\n",
      ".MsqE13: 81.16211267736738\n",
      ".MsqE14: 99.48390029857845\n",
      ".MsqE15: 53.54519695294328\n",
      ".MsqE16: 52.12736571722432\n",
      ".MsqE17: 49.4908289492709\n",
      ".MsqE18: 56.71992209968443\n",
      ".MsqE19: 46.743236405949766\n",
      ".MsqE20: 53.26810603465849\n",
      ".MsqE21: 44.76849483749241\n",
      ".MsqE22: 47.137735706317\n",
      ".MsqE23: 55.09545534251191\n",
      ".MsqE24: 53.61364974481774\n",
      ".MsqE25: 49.29740425529604\n",
      ".MsqE26: 60.07863720643868\n",
      ".MsqE27: 73.04058637896787\n",
      ".MsqE28: 64.78380235344846\n",
      ".MsqE29: 54.252942353776355\n",
      ".MsqE30: 52.00625714052071\n",
      ".MsqE31: 54.385240190623264\n",
      ".MsqE32: 50.91816250946144\n",
      ".MsqE33: 48.7551111758334\n",
      ".MsqE34: 50.729433917690635\n",
      ".MsqE35: 62.30237576876643\n",
      ".MsqE36: 56.26368972630177\n",
      ".MsqE37: 58.55486088971875\n",
      ".MsqE38: 64.64809321431281\n",
      ".MsqE39: 55.86786141750496\n",
      ".MsqE40: 45.34870350167975\n",
      ".MsqE41: 62.085370295256084\n",
      ".MsqE42: 46.98595309951931\n",
      ".MsqE43: 52.52595301507746\n",
      ".MsqE44: 61.78708135117219\n",
      ".MsqE45: 58.19948123573871\n",
      ".MsqE46: 55.65097253299454\n",
      ".MsqE47: 51.385563304123366\n",
      ".MsqE48: 51.894229209924596\n",
      ".MsqE49: 54.17202824219145\n",
      ".MsqE50: 63.94352608591222\n",
      ".End!\n"
     ]
    }
   ],
   "source": [
    "n_mean_squared_errors = 50\n",
    "epochs = 50\n",
    "mean_squared_errors = []\n",
    "for i in range(0, 50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)\n",
    "    model.fit(X_train, y_train, epochs = epochs, verbose = 0)\n",
    "    MsqE = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    print(\"MsqE\" +str(i + 1)+\": \"+str(MsqE))\n",
    "    y_pred = model.predict(X_test)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors.append(MSE)\n",
    "    print('.', end='')\n",
    "print('End!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared errors of 50 regression models: mean = 71.153, standard deviation = 28.072\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(mean_squared_errors)\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "print(\"The mean squared errors of 50 regression models: mean = %.3f, standard deviation = %.3f\" %(mean, standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B - Normalizing the data and repeating part A steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = (X - X.mean()) / X.std()\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X_norm.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the regression model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "\n",
    "X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 1s 853us/step - loss: 1547.5741\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 309us/step - loss: 1531.2023\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 355us/step - loss: 1515.1619\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 300us/step - loss: 1499.2823\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 332us/step - loss: 1483.5743\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 280us/step - loss: 1467.6576\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 308us/step - loss: 1451.6607\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 305us/step - loss: 1435.0997\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 358us/step - loss: 1418.3394\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 331us/step - loss: 1400.8685\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 636us/step - loss: 1382.7954\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 355us/step - loss: 1363.7351\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 360us/step - loss: 1343.9577\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 304us/step - loss: 1323.6698\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 419us/step - loss: 1302.1567\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 310us/step - loss: 1280.3115\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 276us/step - loss: 1256.9876\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 304us/step - loss: 1233.4950\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 469us/step - loss: 1208.5966\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 413us/step - loss: 1183.5971\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 283us/step - loss: 1157.6057\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 362us/step - loss: 1130.8270\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 342us/step - loss: 1103.7553\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 323us/step - loss: 1076.49860s - loss: 1085.06\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 414us/step - loss: 1048.5187\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 330us/step - loss: 1020.5131\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 342us/step - loss: 992.2542\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 348us/step - loss: 964.3350\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 279us/step - loss: 936.1401\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 301us/step - loss: 907.9199\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 364us/step - loss: 879.4889\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 365us/step - loss: 851.3819\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 322us/step - loss: 823.8704\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 305us/step - loss: 796.5277\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 329us/step - loss: 769.2092\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 385us/step - loss: 742.7659\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 335us/step - loss: 716.6210\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 331us/step - loss: 690.9313\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 309us/step - loss: 666.1701\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 277us/step - loss: 641.7987\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 420us/step - loss: 618.6432\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 304us/step - loss: 595.7247\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 307us/step - loss: 573.9851\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 366us/step - loss: 552.8359\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 282us/step - loss: 532.3830\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 301us/step - loss: 512.5796\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 384us/step - loss: 493.4236\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 387us/step - loss: 474.4975\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 330us/step - loss: 456.6667\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 278us/step - loss: 438.9261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44dc6ea3c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = regression_model()\n",
    "model.fit(X_norm_train, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on the test data is 457.688\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_norm_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error on the test data is %.3f\" %(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated steps 1-3 50 times using a for-loop\n",
    "## With means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MsE1: 95.18161658870363\n",
      ".MsE2: 118.43436634347663\n",
      ".MsE3: 104.83406121213845\n",
      ".MsE4: 114.41845117957847\n",
      ".MsE5: 111.14443391966589\n",
      ".MsE6: 96.08330069236385\n",
      ".MsE7: 106.55319169424112\n",
      ".MsE8: 78.38717021756959\n",
      ".MsE9: 85.12673824273267\n",
      ".MsE10: 74.71829038453333\n",
      ".MsE11: 69.19914280172304\n",
      ".MsE12: 63.65630520817531\n",
      ".MsE13: 77.33818318388609\n",
      ".MsE14: 78.35761396784612\n",
      ".MsE15: 68.29302615563846\n",
      ".MsE16: 64.91700502661054\n",
      ".MsE17: 66.40280724189043\n",
      ".MsE18: 68.32060477494421\n",
      ".MsE19: 62.6908458968968\n",
      ".MsE20: 71.36093901353361\n",
      ".MsE21: 59.18636650406427\n",
      ".MsE22: 71.92019280492295\n",
      ".MsE23: 58.45836225836794\n",
      ".MsE24: 52.882749674775454\n",
      ".MsE25: 54.218514501084016\n",
      ".MsE26: 55.70596444336728\n",
      ".MsE27: 48.75875785358515\n",
      ".MsE28: 54.34585272532836\n",
      ".MsE29: 49.87145752891368\n",
      ".MsE30: 44.12826382535175\n",
      ".MsE31: 43.32750615487207\n",
      ".MsE32: 41.76928735010832\n",
      ".MsE33: 43.80153283177842\n",
      ".MsE34: 42.88184829514389\n",
      ".MsE35: 42.26286614674195\n",
      ".MsE36: 49.85460073971054\n",
      ".MsE37: 40.23496526576169\n",
      ".MsE38: 43.6721770894566\n",
      ".MsE39: 39.0193802052717\n",
      ".MsE40: 36.172381934996174\n",
      ".MsE41: 39.46842886174767\n",
      ".MsE42: 37.15082874730181\n",
      ".MsE43: 39.1335541129498\n",
      ".MsE44: 44.44324374893337\n",
      ".MsE45: 43.69442234224486\n",
      ".MsE46: 41.55020760101022\n",
      ".MsE47: 38.866597333000705\n",
      ".MsE48: 40.68430262939058\n",
      ".MsE49: 42.78252359038418\n",
      ".MsE50: 41.28778847135772\n",
      ".End!\n"
     ]
    }
   ],
   "source": [
    "n_mean_squared_errors = 50\n",
    "epochs = 50\n",
    "mean_squared_errors = []\n",
    "for i in range(0, 50):\n",
    "    X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3, random_state = i)\n",
    "    model.fit(X_norm_train, y_train, epochs = epochs, verbose = 0)\n",
    "    MsE = model.evaluate(X_norm_test, y_test, verbose = 0)\n",
    "    print(\"MsE\" +str(i + 1)+\": \"+str(MsE))\n",
    "    y_pred = model.predict(X_norm_test)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors.append(MSE)\n",
    "    print('.', end='')\n",
    "print('End!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared errors of 50 regression models: mean = 61.139, standard deviation = 22.631\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(mean_squared_errors)\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "print(\"The mean squared errors of 50 regression models: mean = %.3f, standard deviation = %.3f\" %(mean, standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: How does the mean of the mean squared errors compared to that from step A? The mean of 61.139 is lower than the mean of 71.153 from step A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C - Repeating Part B, but using 100 epochs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "721/721 [==============================] - 1s 834us/step - loss: 1615.9509\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 0s 328us/step - loss: 1598.7875\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 0s 302us/step - loss: 1581.7893\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 0s 300us/step - loss: 1564.3656\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 0s 306us/step - loss: 1547.0319\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 0s 395us/step - loss: 1529.2113\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 0s 325us/step - loss: 1510.6158\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 0s 283us/step - loss: 1491.3412\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 1471.4669\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 0s 326us/step - loss: 1449.7744\n",
      "Epoch 11/100\n",
      "721/721 [==============================] - 0s 331us/step - loss: 1427.7274\n",
      "Epoch 12/100\n",
      "721/721 [==============================] - 0s 307us/step - loss: 1404.0592\n",
      "Epoch 13/100\n",
      "721/721 [==============================] - 0s 384us/step - loss: 1379.3227\n",
      "Epoch 14/100\n",
      "721/721 [==============================] - 0s 336us/step - loss: 1352.9216\n",
      "Epoch 15/100\n",
      "721/721 [==============================] - 0s 583us/step - loss: 1325.4534\n",
      "Epoch 16/100\n",
      "721/721 [==============================] - 0s 332us/step - loss: 1296.7623\n",
      "Epoch 17/100\n",
      "721/721 [==============================] - 0s 337us/step - loss: 1266.7038\n",
      "Epoch 18/100\n",
      "721/721 [==============================] - 0s 409us/step - loss: 1235.9091\n",
      "Epoch 19/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 1204.1932\n",
      "Epoch 20/100\n",
      "721/721 [==============================] - 0s 335us/step - loss: 1171.8289\n",
      "Epoch 21/100\n",
      "721/721 [==============================] - 0s 327us/step - loss: 1138.4628\n",
      "Epoch 22/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 1104.9250\n",
      "Epoch 23/100\n",
      "721/721 [==============================] - 0s 279us/step - loss: 1070.9847\n",
      "Epoch 24/100\n",
      "721/721 [==============================] - 0s 249us/step - loss: 1037.1112\n",
      "Epoch 25/100\n",
      "721/721 [==============================] - 0s 328us/step - loss: 1002.7748\n",
      "Epoch 26/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 968.7652\n",
      "Epoch 27/100\n",
      "721/721 [==============================] - 0s 304us/step - loss: 934.7964\n",
      "Epoch 28/100\n",
      "721/721 [==============================] - 0s 503us/step - loss: 901.1146\n",
      "Epoch 29/100\n",
      "721/721 [==============================] - 0s 331us/step - loss: 868.0263\n",
      "Epoch 30/100\n",
      "721/721 [==============================] - 0s 383us/step - loss: 835.2560\n",
      "Epoch 31/100\n",
      "721/721 [==============================] - 0s 303us/step - loss: 802.7794\n",
      "Epoch 32/100\n",
      "721/721 [==============================] - 0s 337us/step - loss: 771.2899\n",
      "Epoch 33/100\n",
      "721/721 [==============================] - 0s 384us/step - loss: 740.1006\n",
      "Epoch 34/100\n",
      "721/721 [==============================] - 0s 384us/step - loss: 709.5686\n",
      "Epoch 35/100\n",
      "721/721 [==============================] - 0s 374us/step - loss: 680.6539\n",
      "Epoch 36/100\n",
      "721/721 [==============================] - 0s 270us/step - loss: 652.2550\n",
      "Epoch 37/100\n",
      "721/721 [==============================] - 0s 378us/step - loss: 624.8333\n",
      "Epoch 38/100\n",
      "721/721 [==============================] - 0s 311us/step - loss: 599.1477\n",
      "Epoch 39/100\n",
      "721/721 [==============================] - 0s 323us/step - loss: 573.9534\n",
      "Epoch 40/100\n",
      "721/721 [==============================] - 0s 359us/step - loss: 550.0052\n",
      "Epoch 41/100\n",
      "721/721 [==============================] - 0s 306us/step - loss: 527.5778\n",
      "Epoch 42/100\n",
      "721/721 [==============================] - 0s 527us/step - loss: 505.8962\n",
      "Epoch 43/100\n",
      "721/721 [==============================] - 0s 310us/step - loss: 485.5744\n",
      "Epoch 44/100\n",
      "721/721 [==============================] - 0s 327us/step - loss: 466.3900\n",
      "Epoch 45/100\n",
      "721/721 [==============================] - 0s 306us/step - loss: 447.9595\n",
      "Epoch 46/100\n",
      "721/721 [==============================] - 0s 587us/step - loss: 430.9939\n",
      "Epoch 47/100\n",
      "721/721 [==============================] - 0s 382us/step - loss: 415.0183\n",
      "Epoch 48/100\n",
      "721/721 [==============================] - 0s 303us/step - loss: 400.0830\n",
      "Epoch 49/100\n",
      "721/721 [==============================] - 0s 302us/step - loss: 385.8725\n",
      "Epoch 50/100\n",
      "721/721 [==============================] - 0s 359us/step - loss: 372.8975\n",
      "Epoch 51/100\n",
      "721/721 [==============================] - 0s 307us/step - loss: 360.5293\n",
      "Epoch 52/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 349.2820\n",
      "Epoch 53/100\n",
      "721/721 [==============================] - 0s 311us/step - loss: 338.5163\n",
      "Epoch 54/100\n",
      "721/721 [==============================] - 0s 294us/step - loss: 328.9873\n",
      "Epoch 55/100\n",
      "721/721 [==============================] - 0s 310us/step - loss: 319.9283\n",
      "Epoch 56/100\n",
      "721/721 [==============================] - 0s 248us/step - loss: 311.8169\n",
      "Epoch 57/100\n",
      "721/721 [==============================] - 0s 304us/step - loss: 304.1386\n",
      "Epoch 58/100\n",
      "721/721 [==============================] - 0s 275us/step - loss: 296.9447\n",
      "Epoch 59/100\n",
      "721/721 [==============================] - 0s 331us/step - loss: 290.4624\n",
      "Epoch 60/100\n",
      "721/721 [==============================] - 0s 446us/step - loss: 284.3622\n",
      "Epoch 61/100\n",
      "721/721 [==============================] - 0s 307us/step - loss: 278.9721\n",
      "Epoch 62/100\n",
      "721/721 [==============================] - 0s 366us/step - loss: 273.5634\n",
      "Epoch 63/100\n",
      "721/721 [==============================] - 0s 329us/step - loss: 268.7073\n",
      "Epoch 64/100\n",
      "721/721 [==============================] - 0s 357us/step - loss: 264.1140\n",
      "Epoch 65/100\n",
      "721/721 [==============================] - 0s 358us/step - loss: 259.8981\n",
      "Epoch 66/100\n",
      "721/721 [==============================] - 0s 382us/step - loss: 255.7318\n",
      "Epoch 67/100\n",
      "721/721 [==============================] - 0s 333us/step - loss: 252.0238\n",
      "Epoch 68/100\n",
      "721/721 [==============================] - 0s 392us/step - loss: 248.3246\n",
      "Epoch 69/100\n",
      "721/721 [==============================] - 0s 322us/step - loss: 244.8642\n",
      "Epoch 70/100\n",
      "721/721 [==============================] - 0s 284us/step - loss: 241.5021\n",
      "Epoch 71/100\n",
      "721/721 [==============================] - 0s 383us/step - loss: 238.3743\n",
      "Epoch 72/100\n",
      "721/721 [==============================] - 0s 305us/step - loss: 235.3792\n",
      "Epoch 73/100\n",
      "721/721 [==============================] - 0s 356us/step - loss: 232.4780\n",
      "Epoch 74/100\n",
      "721/721 [==============================] - 0s 332us/step - loss: 229.7440\n",
      "Epoch 75/100\n",
      "721/721 [==============================] - 0s 373us/step - loss: 226.9861\n",
      "Epoch 76/100\n",
      "721/721 [==============================] - 0s 309us/step - loss: 224.4418\n",
      "Epoch 77/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 221.9558\n",
      "Epoch 78/100\n",
      "721/721 [==============================] - 0s 420us/step - loss: 219.4565\n",
      "Epoch 79/100\n",
      "721/721 [==============================] - 0s 417us/step - loss: 217.1675\n",
      "Epoch 80/100\n",
      "721/721 [==============================] - 0s 325us/step - loss: 214.8031\n",
      "Epoch 81/100\n",
      "721/721 [==============================] - 0s 336us/step - loss: 212.5071\n",
      "Epoch 82/100\n",
      "721/721 [==============================] - 0s 362us/step - loss: 210.2814 0s - loss: 219.4\n",
      "Epoch 83/100\n",
      "721/721 [==============================] - 0s 301us/step - loss: 208.1347\n",
      "Epoch 84/100\n",
      "721/721 [==============================] - 0s 305us/step - loss: 206.0391\n",
      "Epoch 85/100\n",
      "721/721 [==============================] - 0s 305us/step - loss: 203.9017\n",
      "Epoch 86/100\n",
      "721/721 [==============================] - 0s 304us/step - loss: 201.8355\n",
      "Epoch 87/100\n",
      "721/721 [==============================] - 0s 275us/step - loss: 199.8458\n",
      "Epoch 88/100\n",
      "721/721 [==============================] - 0s 306us/step - loss: 197.7616\n",
      "Epoch 89/100\n",
      "721/721 [==============================] - 0s 331us/step - loss: 195.6797\n",
      "Epoch 90/100\n",
      "721/721 [==============================] - 0s 328us/step - loss: 193.7090\n",
      "Epoch 91/100\n",
      "721/721 [==============================] - 0s 307us/step - loss: 191.6864 0s - loss: 190.138\n",
      "Epoch 92/100\n",
      "721/721 [==============================] - 0s 306us/step - loss: 189.6777\n",
      "Epoch 93/100\n",
      "721/721 [==============================] - 0s 305us/step - loss: 187.6827\n",
      "Epoch 94/100\n",
      "721/721 [==============================] - 0s 255us/step - loss: 185.6547\n",
      "Epoch 95/100\n",
      "721/721 [==============================] - 0s 303us/step - loss: 183.8279\n",
      "Epoch 96/100\n",
      "721/721 [==============================] - 0s 309us/step - loss: 181.9148\n",
      "Epoch 97/100\n",
      "721/721 [==============================] - 0s 304us/step - loss: 179.9431\n",
      "Epoch 98/100\n",
      "721/721 [==============================] - 0s 383us/step - loss: 178.0576\n",
      "Epoch 99/100\n",
      "721/721 [==============================] - 0s 330us/step - loss: 176.0632\n",
      "Epoch 100/100\n",
      "721/721 [==============================] - 0s 331us/step - loss: 174.1814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44917aa6a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = regression_model()\n",
    "model.fit(X_norm_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated steps 1-3 50 times using a for-loop\n",
    "## With means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MsE1: 28.20871966710754\n",
      ".MsE2: 28.701945554862903\n",
      ".MsE3: 26.85003960865601\n",
      ".MsE4: 28.754442116203432\n",
      ".MsE5: 29.173058889444594\n",
      ".MsE6: 29.063732807690272\n",
      ".MsE7: 32.18633444332382\n",
      ".MsE8: 26.094706421145343\n",
      ".MsE9: 29.821905413877616\n",
      ".MsE10: 24.43673788768188\n",
      ".MsE11: 29.096370968618054\n",
      ".MsE12: 28.698902802945728\n",
      ".MsE13: 28.921507032943776\n",
      ".MsE14: 32.62849337383381\n",
      ".MsE15: 30.1164937189096\n",
      ".MsE16: 24.43087262397445\n",
      ".MsE17: 32.06820150949422\n",
      ".MsE18: 29.678994039887364\n",
      ".MsE19: 27.15353046651797\n",
      ".MsE20: 30.559525153397743\n",
      ".MsE21: 26.46144816327635\n",
      ".MsE22: 26.954262576056916\n",
      ".MsE23: 25.829328759202678\n",
      ".MsE24: 27.732937235662465\n",
      ".MsE25: 27.638846147407605\n",
      ".MsE26: 27.689808700462763\n",
      ".MsE27: 26.732618115866455\n",
      ".MsE28: 26.09132799438674\n",
      ".MsE29: 31.351051157732226\n",
      ".MsE30: 27.854092446731517\n",
      ".MsE31: 25.772869005172385\n",
      ".MsE32: 25.64353966944426\n",
      ".MsE33: 24.46673530282326\n",
      ".MsE34: 28.327345888205716\n",
      ".MsE35: 31.544678981250158\n",
      ".MsE36: 32.86586992331693\n",
      ".MsE37: 25.815123530267513\n",
      ".MsE38: 28.602311192978547\n",
      ".MsE39: 27.814830064001978\n",
      ".MsE40: 23.90852937420595\n",
      ".MsE41: 30.868221110124804\n",
      ".MsE42: 25.56275747354748\n",
      ".MsE43: 28.38022461678218\n",
      ".MsE44: 29.827955202763135\n",
      ".MsE45: 31.233254367865406\n",
      ".MsE46: 30.40341085291989\n",
      ".MsE47: 28.166854994196722\n",
      ".MsE48: 27.558833557425192\n",
      ".MsE49: 27.192800639130922\n",
      ".MsE50: 28.3724861206746\n",
      ".End!\n"
     ]
    }
   ],
   "source": [
    "n_mean_squared_errors = 50\n",
    "epochs = 100\n",
    "mean_squared_errors = []\n",
    "for i in range(0,50):\n",
    "    X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3, random_state = i)\n",
    "    model.fit(X_norm_train, y_train, epochs = epochs, verbose = 0)\n",
    "    MsE = model.evaluate(X_norm_test, y_test, verbose = 0)\n",
    "    print(\"MsE\" +str(i + 1)+\": \"+str(MsE))\n",
    "    y_pred = model.predict(X_norm_test)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors.append(MSE)\n",
    "    print('.', end='')\n",
    "print('End!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared errors of 50 regression models: mean = 28.266, standard deviation = 2.225\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(mean_squared_errors)\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "print(\"The mean squared errors of 50 regression models: mean = %.3f, standard deviation = %.3f\" %(mean, standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: How does the mean of the mean squared errors compared to that from step B? The mean of 28.266 is much lower than the mean of 61.139 from step B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART D - Repeating Part B using 3 hidden layers of 10 neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "\n",
    "X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 1s 1ms/step - loss: 1567.3720\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 555us/step - loss: 1538.4464\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 475us/step - loss: 1508.3951\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 439us/step - loss: 1469.2859\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 468us/step - loss: 1412.9785\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 470us/step - loss: 1332.9684\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 499us/step - loss: 1222.4522\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 499us/step - loss: 1067.9127\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 447us/step - loss: 883.5476\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 412us/step - loss: 675.1400\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 423us/step - loss: 486.7313\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 451us/step - loss: 353.6972\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 425us/step - loss: 281.1536\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 501us/step - loss: 251.4396\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 443us/step - loss: 235.7994\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 412us/step - loss: 224.6802\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 501us/step - loss: 215.8668\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 436us/step - loss: 207.8925\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 497us/step - loss: 201.5669\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 471us/step - loss: 195.8143\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 420us/step - loss: 191.4424\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 520us/step - loss: 186.8692\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 472us/step - loss: 182.8852\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 468us/step - loss: 179.3501\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 415us/step - loss: 175.9912\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 1s 747us/step - loss: 173.1820\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 384us/step - loss: 170.0078\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 360us/step - loss: 167.2476\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 387us/step - loss: 164.4269\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 414us/step - loss: 161.7373\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 496us/step - loss: 159.3018\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 1s 720us/step - loss: 157.2180\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 498us/step - loss: 155.1278\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 414us/step - loss: 152.9137\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 418us/step - loss: 151.0468\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 439us/step - loss: 149.0627\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 415us/step - loss: 147.6725\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 414us/step - loss: 146.2021\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 416us/step - loss: 145.1745\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 386us/step - loss: 144.1804\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 415us/step - loss: 142.6335\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 528us/step - loss: 141.2317\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 445us/step - loss: 140.4291\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 423us/step - loss: 139.2236\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 473us/step - loss: 138.0099\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 554us/step - loss: 136.9345\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 477us/step - loss: 136.0784\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 393us/step - loss: 134.9862\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 558us/step - loss: 133.8422\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 495us/step - loss: 132.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44917aa6d8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = regression_model()\n",
    "model.fit(X_norm_train, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated steps 1-3 50 times using a for-loop\n",
    "## With means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MsE1: 94.68186575386517\n",
      ".MsE2: 59.994988907502304\n",
      ".MsE3: 36.55982035417773\n",
      ".MsE4: 37.86330196541104\n",
      ".MsE5: 34.9611834060027\n",
      ".MsE6: 33.32375674571806\n",
      ".MsE7: 35.293529029031404\n",
      ".MsE8: 26.12970684261384\n",
      ".MsE9: 28.877981043942153\n",
      ".MsE10: 25.448458933907418\n",
      ".MsE11: 26.269907972959253\n",
      ".MsE12: 21.59439160985854\n",
      ".MsE13: 29.083642539854573\n",
      ".MsE14: 28.57559936177769\n",
      ".MsE15: 27.284211272946454\n",
      ".MsE16: 19.258243866337157\n",
      ".MsE17: 22.510994179734904\n",
      ".MsE18: 25.95815007354835\n",
      ".MsE19: 24.659487616282835\n",
      ".MsE20: 26.797577842539567\n",
      ".MsE21: 25.963753388537558\n",
      ".MsE22: 24.450119993833276\n",
      ".MsE23: 21.300723714735902\n",
      ".MsE24: 23.368823116265453\n",
      ".MsE25: 24.230691669056718\n",
      ".MsE26: 25.34922137461048\n",
      ".MsE27: 22.400633747137867\n",
      ".MsE28: 23.367122718045625\n",
      ".MsE29: 24.666892795501017\n",
      ".MsE30: 23.744628856868804\n",
      ".MsE31: 19.703332413361682\n",
      ".MsE32: 23.48962896155694\n",
      ".MsE33: 20.52670159694832\n",
      ".MsE34: 22.634982383752718\n",
      ".MsE35: 25.068516987427152\n",
      ".MsE36: 24.23908734244436\n",
      ".MsE37: 18.55989226554204\n",
      ".MsE38: 23.196796071567967\n",
      ".MsE39: 23.297097999301158\n",
      ".MsE40: 20.050965213467002\n",
      ".MsE41: 23.554819619385555\n",
      ".MsE42: 19.560145217623912\n",
      ".MsE43: 22.500811015132175\n",
      ".MsE44: 25.463806121480502\n",
      ".MsE45: 25.280738312063864\n",
      ".MsE46: 20.1090008757261\n",
      ".MsE47: 22.840104865410567\n",
      ".MsE48: 25.56456536845482\n",
      ".MsE49: 21.491702940857525\n",
      ".MsE50: 23.79992228264176\n",
      ".End!\n"
     ]
    }
   ],
   "source": [
    "n_mean_squared_errors = 50\n",
    "epochs = 50\n",
    "mean_squared_errors = []\n",
    "for i in range(0, 50):\n",
    "    X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3, random_state = i)\n",
    "    model.fit(X_norm_train, y_train, epochs = epochs, verbose = 0)\n",
    "    MsE = model.evaluate(X_norm_test, y_test, verbose = 0)\n",
    "    print(\"MsE\" +str(i + 1)+\": \"+str(MsE))\n",
    "    y_pred = model.predict(X_norm_test)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors.append(MSE)\n",
    "    print('.', end='')\n",
    "print('End!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared errors of 50 regression models: mean = 27.098, standard deviation = 11.645\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(mean_squared_errors)\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "print(\"The mean squared errors of 50 regression models: mean = %.3f, standard deviation = %.3f\" %(mean, standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: How does the mean of the mean squared errors compared to that from step B? The mean of 27.098 is much lower than the mean of 61.139 from step B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
